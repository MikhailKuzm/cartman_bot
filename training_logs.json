[
  {
    "loss": 3.0694,
    "grad_norm": 2.8398234844207764,
    "learning_rate": 4.911504424778761e-05,
    "epoch": 0.017699115044247787,
    "step": 10
  },
  {
    "loss": 1.9372,
    "grad_norm": 1.4589937925338745,
    "learning_rate": 4.823008849557522e-05,
    "epoch": 0.035398230088495575,
    "step": 20
  },
  {
    "loss": 1.8173,
    "grad_norm": 1.2666763067245483,
    "learning_rate": 4.734513274336283e-05,
    "epoch": 0.05309734513274336,
    "step": 30
  },
  {
    "loss": 1.8022,
    "grad_norm": 1.2812927961349487,
    "learning_rate": 4.646017699115045e-05,
    "epoch": 0.07079646017699115,
    "step": 40
  },
  {
    "loss": 1.7473,
    "grad_norm": 2.1204826831817627,
    "learning_rate": 4.5575221238938055e-05,
    "epoch": 0.08849557522123894,
    "step": 50
  },
  {
    "loss": 1.7583,
    "grad_norm": 1.1663177013397217,
    "learning_rate": 4.469026548672566e-05,
    "epoch": 0.10619469026548672,
    "step": 60
  },
  {
    "loss": 1.6935,
    "grad_norm": 1.1128865480422974,
    "learning_rate": 4.380530973451328e-05,
    "epoch": 0.12389380530973451,
    "step": 70
  },
  {
    "loss": 1.7246,
    "grad_norm": 1.1626688241958618,
    "learning_rate": 4.2920353982300885e-05,
    "epoch": 0.1415929203539823,
    "step": 80
  },
  {
    "loss": 1.6873,
    "grad_norm": 1.0684908628463745,
    "learning_rate": 4.20353982300885e-05,
    "epoch": 0.1592920353982301,
    "step": 90
  },
  {
    "loss": 1.6944,
    "grad_norm": 1.0988179445266724,
    "learning_rate": 4.115044247787611e-05,
    "epoch": 0.17699115044247787,
    "step": 100
  },
  {
    "loss": 1.7246,
    "grad_norm": 1.0470741987228394,
    "learning_rate": 4.026548672566372e-05,
    "epoch": 0.19469026548672566,
    "step": 110
  },
  {
    "loss": 1.7021,
    "grad_norm": 1.0902656316757202,
    "learning_rate": 3.938053097345133e-05,
    "epoch": 0.21238938053097345,
    "step": 120
  },
  {
    "loss": 1.6618,
    "grad_norm": 1.110954999923706,
    "learning_rate": 3.849557522123894e-05,
    "epoch": 0.23008849557522124,
    "step": 130
  },
  {
    "loss": 1.559,
    "grad_norm": 0.8652489185333252,
    "learning_rate": 3.7610619469026545e-05,
    "epoch": 0.24778761061946902,
    "step": 140
  },
  {
    "loss": 1.7141,
    "grad_norm": 1.1615647077560425,
    "learning_rate": 3.672566371681416e-05,
    "epoch": 0.26548672566371684,
    "step": 150
  },
  {
    "loss": 1.6937,
    "grad_norm": 1.0417739152908325,
    "learning_rate": 3.5840707964601774e-05,
    "epoch": 0.2831858407079646,
    "step": 160
  },
  {
    "loss": 1.6333,
    "grad_norm": 1.2972335815429688,
    "learning_rate": 3.495575221238938e-05,
    "epoch": 0.3008849557522124,
    "step": 170
  },
  {
    "loss": 1.7006,
    "grad_norm": 1.0833091735839844,
    "learning_rate": 3.407079646017699e-05,
    "epoch": 0.3185840707964602,
    "step": 180
  },
  {
    "loss": 1.6829,
    "grad_norm": 1.3916447162628174,
    "learning_rate": 3.3185840707964604e-05,
    "epoch": 0.336283185840708,
    "step": 190
  },
  {
    "loss": 1.5472,
    "grad_norm": 1.0992532968521118,
    "learning_rate": 3.230088495575221e-05,
    "epoch": 0.35398230088495575,
    "step": 200
  },
  {
    "loss": 1.636,
    "grad_norm": 1.0553990602493286,
    "learning_rate": 3.1415929203539826e-05,
    "epoch": 0.37168141592920356,
    "step": 210
  },
  {
    "loss": 1.609,
    "grad_norm": 1.1032960414886475,
    "learning_rate": 3.0530973451327434e-05,
    "epoch": 0.3893805309734513,
    "step": 220
  },
  {
    "loss": 1.5672,
    "grad_norm": 1.0370851755142212,
    "learning_rate": 2.964601769911505e-05,
    "epoch": 0.40707964601769914,
    "step": 230
  },
  {
    "loss": 1.5929,
    "grad_norm": 1.2078675031661987,
    "learning_rate": 2.8761061946902656e-05,
    "epoch": 0.4247787610619469,
    "step": 240
  },
  {
    "loss": 1.6588,
    "grad_norm": 1.168871283531189,
    "learning_rate": 2.7876106194690264e-05,
    "epoch": 0.4424778761061947,
    "step": 250
  },
  {
    "loss": 1.6461,
    "grad_norm": 1.1356414556503296,
    "learning_rate": 2.6991150442477875e-05,
    "epoch": 0.46017699115044247,
    "step": 260
  },
  {
    "loss": 1.5934,
    "grad_norm": 0.9362787008285522,
    "learning_rate": 2.610619469026549e-05,
    "epoch": 0.4778761061946903,
    "step": 270
  },
  {
    "loss": 1.5891,
    "grad_norm": 0.9661362171173096,
    "learning_rate": 2.5221238938053098e-05,
    "epoch": 0.49557522123893805,
    "step": 280
  },
  {
    "loss": 1.6388,
    "grad_norm": 1.4980828762054443,
    "learning_rate": 2.433628318584071e-05,
    "epoch": 0.5132743362831859,
    "step": 290
  },
  {
    "loss": 1.5395,
    "grad_norm": 0.9711464047431946,
    "learning_rate": 2.345132743362832e-05,
    "epoch": 0.5309734513274337,
    "step": 300
  },
  {
    "loss": 1.6058,
    "grad_norm": 1.0660221576690674,
    "learning_rate": 2.2566371681415928e-05,
    "epoch": 0.5486725663716814,
    "step": 310
  },
  {
    "loss": 1.5961,
    "grad_norm": 1.0830246210098267,
    "learning_rate": 2.1681415929203542e-05,
    "epoch": 0.5663716814159292,
    "step": 320
  },
  {
    "loss": 1.5976,
    "grad_norm": 1.0461671352386475,
    "learning_rate": 2.079646017699115e-05,
    "epoch": 0.584070796460177,
    "step": 330
  },
  {
    "loss": 1.4989,
    "grad_norm": 0.9257256984710693,
    "learning_rate": 1.991150442477876e-05,
    "epoch": 0.6017699115044248,
    "step": 340
  },
  {
    "loss": 1.6178,
    "grad_norm": 1.0602434873580933,
    "learning_rate": 1.9026548672566372e-05,
    "epoch": 0.6194690265486725,
    "step": 350
  },
  {
    "loss": 1.6069,
    "grad_norm": 1.0651745796203613,
    "learning_rate": 1.8141592920353983e-05,
    "epoch": 0.6371681415929203,
    "step": 360
  },
  {
    "loss": 1.5414,
    "grad_norm": 1.093061089515686,
    "learning_rate": 1.7256637168141594e-05,
    "epoch": 0.6548672566371682,
    "step": 370
  },
  {
    "loss": 1.5933,
    "grad_norm": 0.9061571359634399,
    "learning_rate": 1.6371681415929206e-05,
    "epoch": 0.672566371681416,
    "step": 380
  },
  {
    "loss": 1.6091,
    "grad_norm": 1.1478666067123413,
    "learning_rate": 1.5486725663716813e-05,
    "epoch": 0.6902654867256637,
    "step": 390
  },
  {
    "loss": 1.5065,
    "grad_norm": 1.0785342454910278,
    "learning_rate": 1.4601769911504426e-05,
    "epoch": 0.7079646017699115,
    "step": 400
  },
  {
    "loss": 1.563,
    "grad_norm": 1.060070514678955,
    "learning_rate": 1.3716814159292036e-05,
    "epoch": 0.7256637168141593,
    "step": 410
  },
  {
    "loss": 1.5426,
    "grad_norm": 1.042732834815979,
    "learning_rate": 1.2831858407079647e-05,
    "epoch": 0.7433628318584071,
    "step": 420
  },
  {
    "loss": 1.6692,
    "grad_norm": 1.0847036838531494,
    "learning_rate": 1.1946902654867258e-05,
    "epoch": 0.7610619469026548,
    "step": 430
  },
  {
    "loss": 1.5901,
    "grad_norm": 1.0871727466583252,
    "learning_rate": 1.1061946902654869e-05,
    "epoch": 0.7787610619469026,
    "step": 440
  },
  {
    "loss": 1.5303,
    "grad_norm": 1.0747559070587158,
    "learning_rate": 1.0176991150442479e-05,
    "epoch": 0.7964601769911505,
    "step": 450
  },
  {
    "loss": 1.5932,
    "grad_norm": 1.110305666923523,
    "learning_rate": 9.29203539823009e-06,
    "epoch": 0.8141592920353983,
    "step": 460
  },
  {
    "loss": 1.5832,
    "grad_norm": 1.1167211532592773,
    "learning_rate": 8.407079646017701e-06,
    "epoch": 0.831858407079646,
    "step": 470
  },
  {
    "loss": 1.4874,
    "grad_norm": 0.8411738872528076,
    "learning_rate": 7.52212389380531e-06,
    "epoch": 0.8495575221238938,
    "step": 480
  },
  {
    "loss": 1.5032,
    "grad_norm": 1.109429955482483,
    "learning_rate": 6.6371681415929215e-06,
    "epoch": 0.8672566371681416,
    "step": 490
  },
  {
    "loss": 1.5664,
    "grad_norm": 1.0780160427093506,
    "learning_rate": 5.752212389380531e-06,
    "epoch": 0.8849557522123894,
    "step": 500
  },
  {
    "loss": 1.6252,
    "grad_norm": 1.0509132146835327,
    "learning_rate": 4.867256637168142e-06,
    "epoch": 0.9026548672566371,
    "step": 510
  },
  {
    "loss": 1.5563,
    "grad_norm": 1.15118408203125,
    "learning_rate": 3.982300884955752e-06,
    "epoch": 0.9203539823008849,
    "step": 520
  },
  {
    "loss": 1.5666,
    "grad_norm": 1.0900039672851562,
    "learning_rate": 3.097345132743363e-06,
    "epoch": 0.9380530973451328,
    "step": 530
  },
  {
    "loss": 1.5986,
    "grad_norm": 1.0846118927001953,
    "learning_rate": 2.2123893805309734e-06,
    "epoch": 0.9557522123893806,
    "step": 540
  },
  {
    "loss": 1.549,
    "grad_norm": 1.0140821933746338,
    "learning_rate": 1.3274336283185841e-06,
    "epoch": 0.9734513274336283,
    "step": 550
  },
  {
    "loss": 1.5775,
    "grad_norm": 1.0749861001968384,
    "learning_rate": 4.424778761061947e-07,
    "epoch": 0.9911504424778761,
    "step": 560
  },
  {
    "eval_loss": 1.5278748273849487,
    "eval_runtime": 22.0861,
    "eval_samples_per_second": 21.507,
    "eval_steps_per_second": 1.358,
    "epoch": 1.0,
    "step": 565
  },
  {
    "train_runtime": 3048.6277,
    "train_samples_per_second": 2.96,
    "train_steps_per_second": 0.185,
    "total_flos": 2358160588800000.0,
    "train_loss": 1.6504747238834347,
    "epoch": 1.0,
    "step": 565
  }
]